{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":50160,"databundleVersionId":7921029,"sourceType":"competition"},{"sourceId":8493032,"sourceType":"datasetVersion","datasetId":5067269},{"sourceId":8493041,"sourceType":"datasetVersion","datasetId":5067278},{"sourceId":179682191,"sourceType":"kernelVersion"}],"dockerImageVersionId":30699,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":26523.788386,"end_time":"2024-05-22T07:40:27.937926","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-05-22T00:18:24.149540","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %%capture\n!python /kaggle/usr/lib/pipeline1_final/pipeline1_final.py","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:24:10.618481Z","iopub.execute_input":"2024-05-26T13:24:10.618832Z","iopub.status.idle":"2024-05-26T13:28:43.511557Z","shell.execute_reply.started":"2024-05-26T13:24:10.618793Z","shell.execute_reply":"2024-05-26T13:28:43.510609Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"train data shape:\t (1526659, 861)\n389\n['max_collater_typofvalofguarant_298M', 'last_familystate_726L', 'max_financialinstitution_382M', 'max_incometype_1044T', 'max_remitter_829L', 'paytype_783L', 'max_subjectrole_93M', 'last_purposeofcred_874M', 'opencred_647L', 'last_classificationofcontr_13M', 'last_language1_981M', 'last_contaddr_smempladdr_334L', 'last_education_927M', 'last_subjectrole_93M', 'max_empladdr_district_926M', 'max_rejectreason_755M', 'last_role_1084L', 'last_collaterals_typeofguarante_359M', 'max_conts_type_509L', 'max_cancelreason_3545846M', 'max_conts_role_79M', 'max_inittransactioncode_279L', 'max_classificationofcontr_13M', 'last_relationshiptoclient_642T', 'max_description_351M', 'last_sex_738L', 'last_collater_typofvalofguarant_407M', 'last_subjectroles_name_541M', 'max_education_1138M', 'last_purposeofcred_426M', 'maritalst_385M', 'last_cancelreason_3545846M', 'max_purposeofcred_426M', 'last_collater_typofvalofguarant_298M', 'max_contaddr_matchlist_1032L', 'last_isbidproduct_390L', 'max_sex_738L', 'last_conts_type_509L', 'max_collaterals_typeofguarante_669M', 'credtype_322L', 'max_collater_typofvalofguarant_407M', 'lastrejectcommoditycat_161M', 'max_empls_economicalst_849M', 'last_conts_role_79M', 'last_subjectroles_name_838M', 'disbursementtype_67L', 'max_status_219L', 'last_classificationofcontr_400M', 'max_familystate_447L', 'last_status_219L', 'lastst_736L', 'last_rejectreason_755M', 'last_incometype_1044T', 'max_subjectroles_name_838M', 'last_cacccardblochreas_147M', 'last_postype_4733339M', 'description_5085714M', 'max_contaddr_smempladdr_334L', 'last_financialinstitution_591M', 'last_empls_economicalst_849M', 'last_financialinstitution_382M', 'last_safeguarantyflag_411L', 'max_relationshiptoclient_642T', 'education_1103M', 'lastrejectcommodtypec_5251769M', 'last_empls_employer_name_740M', 'last_education_1138M', 'lastrejectreasonclient_4145040M', 'max_contractst_964M', 'max_credtype_587L', 'max_empls_employer_name_740M', 'max_empl_employedtotal_800L', 'requesttype_4525192L', 'max_safeguarantyflag_411L', 'max_postype_4733339M', 'lastcancelreason_561M', 'max_empl_industry_691L', 'max_empladdr_zipcode_114M', 'last_subjectrole_182M', 'maritalst_893M', 'isbidproduct_1095L', 'twobodfilling_608L', 'max_subjectroles_name_541M', 'last_empladdr_zipcode_114M', 'max_contractst_545M', 'max_language1_981M', 'max_cacccardblochreas_147M', 'last_contractst_964M', 'lastrejectreason_759M', 'max_classificationofcontr_400M', 'last_credtype_587L', 'max_collaterals_typeofguarante_359M', 'last_contaddr_matchlist_1032L', 'max_type_25L', 'max_role_1084L', 'last_inittransactioncode_279L', 'last_rejectreasonclient_4145042M', 'max_education_927M', 'max_rejectreasonclient_4145042M', 'max_familystate_726L', 'last_type_25L', 'last_empladdr_district_926M', 'max_isbidproduct_390L', 'inittransactioncode_186L', 'max_purposeofcred_874M', 'max_relationshiptoclient_415T', 'last_collaterals_typeofguarante_669M', 'max_financialinstitution_591M', 'last_description_351M', 'education_88M', 'max_subjectrole_182M', 'last_contractst_545M', 'paytype1st_925L', 'lastapprcommoditycat_1041M']\nMemory usage of dataframe is 4530.87 MB\nMemory usage after optimization is: 2364.44 MB\nDecreased by 47.8%\ngpu\ntest data shape:\t (10, 860)\nMemory usage of dataframe is 0.03 MB\nMemory usage after optimization is: 0.01 MB\nDecreased by 50.6%\ntrain data shape:\t (50000, 389)\ntest data shape:\t (10, 388)\nlen cat_cols:\t 114\ntrain data shape:\t (50000, 462)\ntest data shape:\t (10, 461)\ntrain data shape:\t (50000, 483)\ntest data shape:\t (10, 482)\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\n1 warning generated.\nTraining until validation scores don't improve for 150 rounds\n[200]\tvalid_0's auc: 0.737996\nEarly stopping, best iteration is:\n[185]\tvalid_0's auc: 0.738486\nTraining until validation scores don't improve for 150 rounds\n[200]\tvalid_0's auc: 0.747462\nEarly stopping, best iteration is:\n[149]\tvalid_0's auc: 0.749695\nTraining until validation scores don't improve for 150 rounds\n[200]\tvalid_0's auc: 0.78868\nEarly stopping, best iteration is:\n[150]\tvalid_0's auc: 0.790069\nTraining until validation scores don't improve for 150 rounds\n[200]\tvalid_0's auc: 0.743726\nEarly stopping, best iteration is:\n[199]\tvalid_0's auc: 0.743905\nTraining until validation scores don't improve for 150 rounds\n[200]\tvalid_0's auc: 0.740706\nEarly stopping, best iteration is:\n[187]\tvalid_0's auc: 0.74217\n5\n","output_type":"stream"}]},{"cell_type":"code","source":"import gc\nimport lightgbm as lgb  # type: ignore\nimport numpy as np  # type: ignore\nimport pandas as pd  # type: ignore\nimport polars as pl  # type: ignore\nimport warnings\n\nfrom catboost import CatBoostClassifier, Pool  # type: ignore\nfrom glob import glob\nfrom IPython.display import display  # type: ignore\nfrom pathlib import Path\nfrom sklearn.base import BaseEstimator, ClassifierMixin  # type: ignore\nfrom sklearn.metrics import roc_auc_score  # type: ignore\nfrom sklearn.model_selection import StratifiedGroupKFold  # type: ignore\nfrom typing import Any\nimport joblib\nfrom sklearn.decomposition import PCA\nwarnings.filterwarnings(\"ignore\")\n\nROOT = Path(\"/kaggle/input/home-credit-credit-risk-model-stability\")\nTRAIN_DIR = ROOT / \"parquet_files\" / \"train\"\nTEST_DIR = ROOT / \"parquet_files\" / \"test\"","metadata":{"papermill":{"duration":4.500019,"end_time":"2024-05-22T00:18:31.726609","exception":false,"start_time":"2024-05-22T00:18:27.226590","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:28:43.513700Z","iopub.execute_input":"2024-05-26T13:28:43.514022Z","iopub.status.idle":"2024-05-26T13:28:46.417517Z","shell.execute_reply.started":"2024-05-26T13:28:43.513993Z","shell.execute_reply":"2024-05-26T13:28:46.416500Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class Utility:\n    @staticmethod\n    def get_feat_defs(ending_with: str) -> None:\n        \"\"\"\n        Retrieves feature definitions from a CSV file based on the specified ending.\n\n        Args:\n        - ending_with (str): Ending to filter feature definitions.\n\n        Returns:\n        - pl.DataFrame: Filtered feature definitions.\n        \"\"\"\n        feat_defs: pl.DataFrame = pl.read_csv(ROOT / \"feature_definitions.csv\")\n\n        filtered_feats: pl.DataFrame = feat_defs.filter(\n            pl.col(\"Variable\").apply(lambda var: var.endswith(ending_with))\n        )\n\n        with pl.Config(fmt_str_lengths=200, tbl_rows=-1):\n            print(filtered_feats)\n\n        filtered_feats = None\n        feat_defs = None\n\n    @staticmethod\n    def find_index(lst: list[Any], item: Any) -> int | None:\n        \"\"\"\n        Finds the index of an item in a list.\n\n        Args:\n        - lst (list): List to search.\n        - item (Any): Item to find in the list.\n\n        Returns:\n        - int | None: Index of the item if found, otherwise None.\n        \"\"\"\n        try:\n            return lst.index(item)\n        except ValueError:\n            return None\n\n    @staticmethod\n    def dtype_to_str(dtype: pl.DataType) -> str:\n        \"\"\"\n        Converts Polars data type to string representation.\n\n        Args:\n        - dtype (pl.DataType): Polars data type.\n\n        Returns:\n        - str: String representation of the data type.\n        \"\"\"\n        dtype_map = {\n            pl.Decimal: \"Decimal\",\n            pl.Float32: \"Float32\",\n            pl.Float64: \"Float64\",\n            pl.UInt8: \"UInt8\",\n            pl.UInt16: \"UInt16\",\n            pl.UInt32: \"UInt32\",\n            pl.UInt64: \"UInt64\",\n            pl.Int8: \"Int8\",\n            pl.Int16: \"Int16\",\n            pl.Int32: \"Int32\",\n            pl.Int64: \"Int64\",\n            pl.Date: \"Date\",\n            pl.Datetime: \"Datetime\",\n            pl.Duration: \"Duration\",\n            pl.Time: \"Time\",\n            pl.Array: \"Array\",\n            pl.List: \"List\",\n            pl.Struct: \"Struct\",\n            pl.String: \"String\",\n            pl.Categorical: \"Categorical\",\n            pl.Enum: \"Enum\",\n            pl.Utf8: \"Utf8\",\n            pl.Binary: \"Binary\",\n            pl.Boolean: \"Boolean\",\n            pl.Null: \"Null\",\n            pl.Object: \"Object\",\n            pl.Unknown: \"Unknown\",\n        }\n\n        return dtype_map.get(dtype)\n\n    @staticmethod\n    def find_feat_occur(regex_path: str, ending_with: str) -> pl.DataFrame:\n        \"\"\"\n        Finds occurrences of features ending with a specific string in Parquet files.\n\n        Args:\n        - regex_path (str): Regular expression to match Parquet file paths.\n        - ending_with (str): Ending to filter feature names.\n\n        Returns:\n        - pl.DataFrame: DataFrame containing feature definitions, data types, and file locations.\n        \"\"\"\n        feat_defs: pl.DataFrame = pl.read_csv(ROOT / \"feature_definitions.csv\").filter(\n            pl.col(\"Variable\").apply(lambda var: var.endswith(ending_with))\n        )\n        feat_defs.sort(by=[\"Variable\"])\n\n        feats: list[pl.String] = feat_defs[\"Variable\"].to_list()\n        feats.sort()\n\n        occurrences: list[list] = [[set(), set()] for _ in range(feat_defs.height)]\n\n        for path in glob(str(regex_path)):\n            df_schema: dict = pl.read_parquet_schema(path)\n\n            for feat, dtype in df_schema.items():\n                index: int = Utility.find_index(feats, feat)\n                if index != None:\n                    occurrences[index][0].add(Utility.dtype_to_str(dtype))\n                    occurrences[index][1].add(Path(path).stem)\n\n        data_types: list[str] = [None] * feat_defs.height\n        file_locs: list[str] = [None] * feat_defs.height\n\n        for i, feat in enumerate(feats):\n            data_types[i] = list(occurrences[i][0])\n            file_locs[i] = list(occurrences[i][1])\n\n        feat_defs = feat_defs.with_columns(pl.Series(data_types).alias(\"Data_Type(s)\"))\n        feat_defs = feat_defs.with_columns(pl.Series(file_locs).alias(\"File_Loc(s)\"))\n\n        return feat_defs\n\n    def reduce_memory_usage(df: pl.DataFrame, name) -> pl.DataFrame:\n        \"\"\"\n        Reduces memory usage of a DataFrame by converting column types.\n\n        Args:\n        - df (pl.DataFrame): DataFrame to optimize.\n        - name (str): Name of the DataFrame.\n\n        Returns:\n        - pl.DataFrame: Optimized DataFrame.\n        \"\"\"\n        print(\n            f\"Memory usage of dataframe \\\"{name}\\\" is {round(df.estimated_size('mb'), 4)} MB.\"\n        )\n\n        int_types = [\n            pl.Int8,\n            pl.Int16,\n            pl.Int32,\n            pl.Int64,\n            pl.UInt8,\n            pl.UInt16,\n            pl.UInt32,\n            pl.UInt64,\n        ]\n        float_types = [pl.Float32, pl.Float64]\n\n        for col in df.columns:\n            col_type = df[col].dtype\n            if col_type in int_types + float_types:\n                c_min = df[col].min()\n                c_max = df[col].max()\n\n                if c_min is not None and c_max is not None:\n                    if col_type in int_types:\n                        if c_min >= 0:\n                            if (\n                                c_min >= np.iinfo(np.uint8).min\n                                and c_max <= np.iinfo(np.uint8).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.UInt8))\n                            elif (\n                                c_min >= np.iinfo(np.uint16).min\n                                and c_max <= np.iinfo(np.uint16).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.UInt16))\n                            elif (\n                                c_min >= np.iinfo(np.uint32).min\n                                and c_max <= np.iinfo(np.uint32).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.UInt32))\n                            elif (\n                                c_min >= np.iinfo(np.uint64).min\n                                and c_max <= np.iinfo(np.uint64).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.UInt64))\n                        else:\n                            if (\n                                c_min >= np.iinfo(np.int8).min\n                                and c_max <= np.iinfo(np.int8).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.Int8))\n                            elif (\n                                c_min >= np.iinfo(np.int16).min\n                                and c_max <= np.iinfo(np.int16).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.Int16))\n                            elif (\n                                c_min >= np.iinfo(np.int32).min\n                                and c_max <= np.iinfo(np.int32).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.Int32))\n                            elif (\n                                c_min >= np.iinfo(np.int64).min\n                                and c_max <= np.iinfo(np.int64).max\n                            ):\n                                df = df.with_columns(df[col].cast(pl.Int64))\n                    elif col_type in float_types:\n                        if (\n                            c_min > np.finfo(np.float32).min\n                            and c_max < np.finfo(np.float32).max\n                        ):\n                            df = df.with_columns(df[col].cast(pl.Float32))\n\n        print(\n            f\"Memory usage of dataframe \\\"{name}\\\" became {round(df.estimated_size('mb'), 4)} MB.\"\n        )\n\n        return df\n\n    def to_pandas(df: pl.DataFrame, cat_cols: list[str] = None) -> (pd.DataFrame, list[str]):  # type: ignore\n        \"\"\"\n        Converts a Polars DataFrame to a Pandas DataFrame.\n\n        Args:\n        - df (pl.DataFrame): Polars DataFrame to convert.\n        - cat_cols (list[str]): List of categorical columns. Default is None.\n\n        Returns:\n        - (pd.DataFrame, list[str]): Tuple containing the converted Pandas DataFrame and categorical columns.\n        \"\"\"\n        df: pd.DataFrame = df.to_pandas()\n\n        if cat_cols is None:\n            cat_cols = list(df.select_dtypes(\"object\").columns)\n\n        df[cat_cols] = df[cat_cols].astype(\"str\")\n\n        return df, cat_cols","metadata":{"papermill":{"duration":0.063861,"end_time":"2024-05-22T00:18:31.803787","exception":false,"start_time":"2024-05-22T00:18:31.739926","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:28:46.419078Z","iopub.execute_input":"2024-05-26T13:28:46.419384Z","iopub.status.idle":"2024-05-26T13:28:46.556586Z","shell.execute_reply.started":"2024-05-26T13:28:46.419358Z","shell.execute_reply":"2024-05-26T13:28:46.555494Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# feat_defs:pl.DataFrame = Utility.find_feat_occur(TRAIN_DIR / \"train_*.parquet\", \"P\")\n# feat_defs:pl.DataFrame = Utility.find_feat_occur(TRAIN_DIR / \"train_*.parquet\", \"M\")\n# feat_defs:pl.DataFrame = Utility.find_feat_occur(TRAIN_DIR / \"train_*.parquet\", \"A\")\n# feat_defs:pl.DataFrame = Utility.find_feat_occur(TRAIN_DIR / \"train_*.parquet\", \"D\")\n# feat_defs:pl.DataFrame = Utility.find_feat_occur(TRAIN_DIR / \"train_*.parquet\", \"T\")\n# feat_defs:pl.DataFrame = Utility.find_feat_occur(TRAIN_DIR / \"train_*.parquet\", \"L\")\n# feat_defs:pl.DataFrame = pl.read_csv(ROOT / \"feature_definitions.csv\")\n# with pl.Config(fmt_str_lengths=1000, tbl_rows=-1, tbl_width_chars=180):\n#     print(feat_defs)","metadata":{"papermill":{"duration":0.018456,"end_time":"2024-05-22T00:18:31.831500","exception":false,"start_time":"2024-05-22T00:18:31.813044","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:28:46.558835Z","iopub.execute_input":"2024-05-26T13:28:46.559164Z","iopub.status.idle":"2024-05-26T13:28:46.575488Z","shell.execute_reply.started":"2024-05-26T13:28:46.559138Z","shell.execute_reply":"2024-05-26T13:28:46.574700Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class Aggregator:\n    @staticmethod\n    def max_expr(df: pl.LazyFrame) -> list[pl.Series]:\n        \"\"\"\n        Generates expressions for calculating maximum values for specific columns.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - list[pl.Series]: List of expressions for maximum values.\n        \"\"\"\n        cols: list[str] = [\n            col\n            for col in df.columns\n            if (col[-1] in (\"P\", \"M\", \"A\", \"D\", \"T\", \"L\")) or (\"num_group\" in col)\n        ]\n\n        expr_max: list[pl.Series] = [\n            pl.col(col).max().alias(f\"max_{col}\") for col in cols\n        ]\n\n        return expr_max\n\n    @staticmethod\n    def last_expr(df: pl.LazyFrame) -> list[pl.Series]:\n        \"\"\"\n        Generates expressions for calculating last values for specific columns.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - list[pl.Series]: List of expressions for last values.\n        \"\"\"\n        cols: list[str] = [\n            col\n            for col in df.columns\n            if (col[-1] in (\"P\", \"M\", \"A\", \"D\", \"T\", \"L\")) or (\"num_group\" in col)\n        ]\n\n        expr_last: list[pl.Series] = [\n            pl.col(col).last().alias(f\"last_{col}\") for col in cols\n        ]\n\n        return expr_last\n    \n    \n    @staticmethod\n    def min_expr(df: pl.LazyFrame) -> list[pl.Series]:\n        \"\"\"\n        Generates expressions for calculating minimum values for specific columns.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - list[pl.Series]: List of expressions for minimum values.\n        \"\"\"\n        cols: list[str] = [\n            col\n            for col in df.columns\n            if (col[-1] in (\"P\", \"M\", \"A\", \"D\", \"T\", \"L\")) or (\"num_group\" in col)\n        ]\n\n        expr_min: list[pl.Series] = [\n            pl.col(col).min().alias(f\"min_{col}\") for col in cols\n        ]\n\n        return expr_min\n\n    @staticmethod\n    def mean_expr(df: pl.LazyFrame) -> list[pl.Series]:\n        \"\"\"\n        Generates expressions for calculating mean values for specific columns.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - list[pl.Series]: List of expressions for mean values.\n        \"\"\"\n        cols: list[str] = [col for col in df.columns if col.endswith((\"P\", \"A\", \"D\"))]\n\n        expr_mean: list[pl.Series] = [\n            pl.col(col).mean().alias(f\"mean_{col}\") for col in cols\n        ]\n\n        return expr_mean\n\n    @staticmethod\n    def var_expr(df: pl.LazyFrame) -> list[pl.Series]:\n        \"\"\"\n        Generates expressions for calculating variance for specific columns.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - list[pl.Series]: List of expressions for variance.\n        \"\"\"\n        cols: list[str] = [col for col in df.columns if col.endswith((\"P\", \"A\", \"D\"))]\n\n        expr_mean: list[pl.Series] = [\n            pl.col(col).var().alias(f\"var_{col}\") for col in cols\n        ]\n\n        return expr_mean\n\n    @staticmethod\n    def mode_expr(df: pl.LazyFrame) -> list[pl.Series]:\n        \"\"\"\n        Generates expressions for calculating mode values for specific columns.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - list[pl.Series]: List of expressions for mode values.\n        \"\"\"\n        cols: list[str] = [col for col in df.columns if col.endswith(\"M\")]\n\n        expr_mode: list[pl.Series] = [\n            pl.col(col).drop_nulls().mode().first().alias(f\"mode_{col}\") for col in cols\n        ]\n\n        return expr_mode\n\n    @staticmethod\n    def get_exprs(df: pl.LazyFrame) -> list[pl.Series]:\n        \"\"\"\n        Combines expressions for maximum, mean, and variance calculations.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - list[pl.Series]: List of combined expressions.\n        \"\"\"\n        exprs = (\n            Aggregator.max_expr(df) + Aggregator.mean_expr(df) + Aggregator.var_expr(df)\n        )\n\n        return exprs","metadata":{"papermill":{"duration":0.03991,"end_time":"2024-05-22T00:18:31.880711","exception":false,"start_time":"2024-05-22T00:18:31.840801","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:28:46.576941Z","iopub.execute_input":"2024-05-26T13:28:46.577235Z","iopub.status.idle":"2024-05-26T13:28:46.596840Z","shell.execute_reply.started":"2024-05-26T13:28:46.577211Z","shell.execute_reply":"2024-05-26T13:28:46.596092Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class SchemaGen:\n    @staticmethod\n    def change_dtypes(df: pl.LazyFrame) -> pl.LazyFrame:\n        \"\"\"\n        Changes the data types of columns in the DataFrame.\n\n        Args:\n        - df (pl.LazyFrame): Input LazyFrame.\n\n        Returns:\n        - pl.LazyFrame: LazyFrame with modified data types.\n        \"\"\"\n        for col in df.columns:\n            if col == \"case_id\":\n                df = df.with_columns(pl.col(col).cast(pl.UInt32).alias(col))\n            elif col in [\"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n                df = df.with_columns(pl.col(col).cast(pl.UInt16).alias(col))\n            elif col == \"date_decision\" or col[-1] == \"D\":\n                df = df.with_columns(pl.col(col).cast(pl.Date).alias(col))\n            elif col[-1] in [\"P\", \"A\"]:\n                df = df.with_columns(pl.col(col).cast(pl.Float64).alias(col))\n            elif col[-1] in (\"M\",):\n                df = df.with_columns(pl.col(col).cast(pl.String))\n        return df\n\n    @staticmethod\n    def scan_files(glob_path: str, depth: int = None) -> pl.LazyFrame:\n        \"\"\"\n        Scans Parquet files matching the glob pattern and combines them into a LazyFrame.\n\n        Args:\n        - glob_path (str): Glob pattern to match Parquet files.\n        - depth (int, optional): Depth level for data aggregation. Defaults to None.\n\n        Returns:\n        - pl.LazyFrame: Combined LazyFrame.\n        \"\"\"\n        chunks: list[pl.LazyFrame] = []\n        for path in glob(str(glob_path)):\n            df: pl.LazyFrame = pl.scan_parquet(\n                path, low_memory=True, rechunk=True\n            ).pipe(SchemaGen.change_dtypes)\n            print(f\"File {Path(path).stem} loaded into memory.\")\n\n            if depth in (1, 2):\n                exprs: list[pl.Series] = Aggregator.get_exprs(df)\n                df = df.group_by(\"case_id\").agg(exprs)\n\n                del exprs\n                gc.collect()\n\n            chunks.append(df)\n\n        df = pl.concat(chunks, how=\"vertical_relaxed\")\n\n        del chunks\n        gc.collect()\n\n        df = df.unique(subset=[\"case_id\"])\n\n        return df\n\n    @staticmethod\n    def join_dataframes(\n        df_base: pl.LazyFrame,\n        depth_0: list[pl.LazyFrame],\n        depth_1: list[pl.LazyFrame],\n        depth_2: list[pl.LazyFrame],\n    ) -> pl.DataFrame:\n        \"\"\"\n        Joins multiple LazyFrames with a base LazyFrame.\n\n        Args:\n        - df_base (pl.LazyFrame): Base LazyFrame.\n        - depth_0 (list[pl.LazyFrame]): List of LazyFrames for depth 0.\n        - depth_1 (list[pl.LazyFrame]): List of LazyFrames for depth 1.\n        - depth_2 (list[pl.LazyFrame]): List of LazyFrames for depth 2.\n\n        Returns:\n        - pl.DataFrame: Joined DataFrame.\n        \"\"\"\n        for i, df in enumerate(depth_0 + depth_1 + depth_2):\n            df_base = df_base.join(df, how=\"left\", on=\"case_id\", suffix=f\"_{i}\")\n\n        return df_base.collect().pipe(Utility.reduce_memory_usage, \"df_train\")","metadata":{"papermill":{"duration":0.03192,"end_time":"2024-05-22T00:18:31.921812","exception":false,"start_time":"2024-05-22T00:18:31.889892","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:28:46.598074Z","iopub.execute_input":"2024-05-26T13:28:46.598367Z","iopub.status.idle":"2024-05-26T13:28:46.617570Z","shell.execute_reply.started":"2024-05-26T13:28:46.598345Z","shell.execute_reply":"2024-05-26T13:28:46.616798Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def filter_cols(df: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"\n    Filters columns in the DataFrame based on null percentage and unique values for string columns.\n\n    Args:\n    - df (pl.DataFrame): Input DataFrame.\n\n    Returns:\n    - pl.DataFrame: DataFrame with filtered columns.\n    \"\"\"\n    for col in df.columns:\n        if col not in [\"case_id\", \"year\", \"month\", \"week_num\", \"target\"]:\n            null_pct = df[col].is_null().mean()\n\n            if null_pct > 0.95:\n                df = df.drop(col)\n\n    for col in df.columns:\n        if (col not in [\"case_id\", \"year\", \"month\", \"week_num\", \"target\"]) & (\n            df[col].dtype == pl.String\n        ):\n            freq = df[col].n_unique()\n\n            if (freq > 200) | (freq == 1):\n                df = df.drop(col)\n\n    return df\n\n\ndef transform_cols(df: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"\n    Transforms columns in the DataFrame according to predefined rules.\n\n    Args:\n    - df (pl.DataFrame): Input DataFrame.\n\n    Returns:\n    - pl.DataFrame: DataFrame with transformed columns.\n    \"\"\"\n    if \"riskassesment_302T\" in df.columns:\n        if df[\"riskassesment_302T\"].dtype == pl.Null:\n            df = df.with_columns(\n                [\n                    pl.Series(\n                        \"riskassesment_302T_rng\", df[\"riskassesment_302T\"], pl.UInt8\n                    ),\n                    pl.Series(\n                        \"riskassesment_302T_mean\", df[\"riskassesment_302T\"], pl.UInt8\n                    ),\n                ]\n            )\n        else:\n            pct_low: pl.Series = (\n                df[\"riskassesment_302T\"]\n                .str.split(\" - \")\n                .apply(lambda x: x[0].replace(\"%\", \"\"))\n                .cast(pl.UInt8)\n            )\n            pct_high: pl.Series = (\n                df[\"riskassesment_302T\"]\n                .str.split(\" - \")\n                .apply(lambda x: x[1].replace(\"%\", \"\"))\n                .cast(pl.UInt8)\n            )\n\n            diff: pl.Series = pct_high - pct_low\n            avg: pl.Series = ((pct_low + pct_high) / 2).cast(pl.Float32)\n\n            del pct_high, pct_low\n            gc.collect()\n\n            df = df.with_columns(\n                [\n                    diff.alias(\"riskassesment_302T_rng\"),\n                    avg.alias(\"riskassesment_302T_mean\"),\n                ]\n            )\n\n        df.drop(\"riskassesment_302T\")\n\n    return df\n\n\ndef handle_dates(df: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"\n    Handles date columns in the DataFrame.\n\n    Args:\n    - df (pl.DataFrame): Input DataFrame.\n\n    Returns:\n    - pl.DataFrame: DataFrame with transformed date columns.\n    \"\"\"\n    for col in df.columns:\n        if col.endswith(\"D\"):\n            df = df.with_columns(pl.col(col) - pl.col(\"date_decision\"))\n            df = df.with_columns(pl.col(col).dt.total_days().cast(pl.Int32))\n\n    df = df.rename(\n        {\n            \"MONTH\": \"month\",\n            \"WEEK_NUM\": \"week_num\"\n        }\n    )\n            \n    df = df.with_columns(\n        [\n            pl.col(\"date_decision\").dt.year().alias(\"year\").cast(pl.Int16),\n            pl.col(\"date_decision\").dt.day().alias(\"day\").cast(pl.UInt8),\n        ]\n    )\n\n    return df.drop(\"date_decision\")","metadata":{"papermill":{"duration":0.037186,"end_time":"2024-05-22T00:18:31.972175","exception":false,"start_time":"2024-05-22T00:18:31.934989","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:28:46.618784Z","iopub.execute_input":"2024-05-26T13:28:46.619140Z","iopub.status.idle":"2024-05-26T13:28:46.638459Z","shell.execute_reply.started":"2024-05-26T13:28:46.619115Z","shell.execute_reply":"2024-05-26T13:28:46.637556Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data_store: dict = {\n    \"df_base\": SchemaGen.scan_files(TRAIN_DIR / \"train_base.parquet\"),\n    \"depth_0\": [\n        SchemaGen.scan_files(TRAIN_DIR / \"train_static_cb_0.parquet\"),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_static_0_*.parquet\"),\n    ],\n    \"depth_1\": [\n        SchemaGen.scan_files(TRAIN_DIR / \"train_applprev_1_*.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_tax_registry_a_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_tax_registry_b_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_tax_registry_c_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_a_1_*.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_b_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_other_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_person_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_deposit_1.parquet\", 1),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_debitcard_1.parquet\", 1),\n    ],\n    \"depth_2\": [\n        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_a_2_*.parquet\", 2),\n        SchemaGen.scan_files(TRAIN_DIR / \"train_credit_bureau_b_2.parquet\", 2),\n    ],\n}\n\ndf_train: pl.LazyFrame = (\n    SchemaGen.join_dataframes(**data_store)\n    .pipe(filter_cols)\n    .pipe(transform_cols)\n    .pipe(handle_dates)\n    .pipe(Utility.reduce_memory_usage, \"df_train\")\n)\n\ndel data_store\ngc.collect()\n\nprint(f\"Train data shape: {df_train.shape}\")\n# display(df_train.head(10))\n\n# df_train.write_parquet(\"train_final.parquet\", compression=\"lz4\")","metadata":{"papermill":{"duration":191.055185,"end_time":"2024-05-22T00:21:43.040570","exception":false,"start_time":"2024-05-22T00:18:31.985385","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:28:46.639646Z","iopub.execute_input":"2024-05-26T13:28:46.640041Z","iopub.status.idle":"2024-05-26T13:31:12.264122Z","shell.execute_reply.started":"2024-05-26T13:28:46.640006Z","shell.execute_reply":"2024-05-26T13:31:12.263206Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"File train_base loaded into memory.\nFile train_static_cb_0 loaded into memory.\nFile train_static_0_0 loaded into memory.\nFile train_static_0_1 loaded into memory.\nFile train_applprev_1_1 loaded into memory.\nFile train_applprev_1_0 loaded into memory.\nFile train_tax_registry_a_1 loaded into memory.\nFile train_tax_registry_b_1 loaded into memory.\nFile train_tax_registry_c_1 loaded into memory.\nFile train_credit_bureau_a_1_3 loaded into memory.\nFile train_credit_bureau_a_1_2 loaded into memory.\nFile train_credit_bureau_a_1_0 loaded into memory.\nFile train_credit_bureau_a_1_1 loaded into memory.\nFile train_credit_bureau_b_1 loaded into memory.\nFile train_other_1 loaded into memory.\nFile train_person_1 loaded into memory.\nFile train_deposit_1 loaded into memory.\nFile train_debitcard_1 loaded into memory.\nFile train_credit_bureau_a_2_6 loaded into memory.\nFile train_credit_bureau_a_2_1 loaded into memory.\nFile train_credit_bureau_a_2_0 loaded into memory.\nFile train_credit_bureau_a_2_7 loaded into memory.\nFile train_credit_bureau_a_2_5 loaded into memory.\nFile train_credit_bureau_a_2_2 loaded into memory.\nFile train_credit_bureau_a_2_4 loaded into memory.\nFile train_credit_bureau_a_2_9 loaded into memory.\nFile train_credit_bureau_a_2_3 loaded into memory.\nFile train_credit_bureau_a_2_10 loaded into memory.\nFile train_credit_bureau_a_2_8 loaded into memory.\nFile train_credit_bureau_b_2 loaded into memory.\nMemory usage of dataframe \"df_train\" is 6783.1317 MB.\nMemory usage of dataframe \"df_train\" became 4174.0953 MB.\nMemory usage of dataframe \"df_train\" is 2870.9171 MB.\nMemory usage of dataframe \"df_train\" became 2665.6302 MB.\nTrain data shape: (1526659, 472)\n","output_type":"stream"}]},{"cell_type":"code","source":"data_store: dict = {\n    \"df_base\": SchemaGen.scan_files(TEST_DIR / \"test_base.parquet\"),\n    \"depth_0\": [\n        SchemaGen.scan_files(TEST_DIR / \"test_static_cb_0.parquet\"),\n        SchemaGen.scan_files(TEST_DIR / \"test_static_0_*.parquet\"),\n    ],\n    \"depth_1\": [\n        SchemaGen.scan_files(TEST_DIR / \"test_applprev_1_*.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_tax_registry_a_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_tax_registry_b_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_tax_registry_c_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_a_1_*.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_b_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_other_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_person_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_deposit_1.parquet\", 1),\n        SchemaGen.scan_files(TEST_DIR / \"test_debitcard_1.parquet\", 1),\n    ],\n    \"depth_2\": [\n        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_a_2_*.parquet\", 2),\n        SchemaGen.scan_files(TEST_DIR / \"test_credit_bureau_b_2.parquet\", 2),\n    ],\n}\n\ndf_test: pl.DataFrame = (\n    SchemaGen.join_dataframes(**data_store)\n    .pipe(transform_cols)\n    .pipe(handle_dates)\n    .select([col for col in df_train.columns if col != \"target\"])\n    .pipe(Utility.reduce_memory_usage, \"df_test\")\n)\n\ndel data_store\ngc.collect()\n\nprint(f\"Test data shape: {df_test.shape}\")\n\n# df_test.write_parquet(\"test_final.parquet\", compression=\"lz4\")","metadata":{"papermill":{"duration":5.370768,"end_time":"2024-05-22T00:21:48.422059","exception":false,"start_time":"2024-05-22T00:21:43.051291","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:31:12.265594Z","iopub.execute_input":"2024-05-26T13:31:12.266037Z","iopub.status.idle":"2024-05-26T13:31:16.289390Z","shell.execute_reply.started":"2024-05-26T13:31:12.266004Z","shell.execute_reply":"2024-05-26T13:31:16.288473Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"File test_base loaded into memory.\nFile test_static_cb_0 loaded into memory.\nFile test_static_0_0 loaded into memory.\nFile test_static_0_2 loaded into memory.\nFile test_static_0_1 loaded into memory.\nFile test_applprev_1_2 loaded into memory.\nFile test_applprev_1_0 loaded into memory.\nFile test_applprev_1_1 loaded into memory.\nFile test_tax_registry_a_1 loaded into memory.\nFile test_tax_registry_b_1 loaded into memory.\nFile test_tax_registry_c_1 loaded into memory.\nFile test_credit_bureau_a_1_3 loaded into memory.\nFile test_credit_bureau_a_1_2 loaded into memory.\nFile test_credit_bureau_a_1_1 loaded into memory.\nFile test_credit_bureau_a_1_4 loaded into memory.\nFile test_credit_bureau_a_1_0 loaded into memory.\nFile test_credit_bureau_b_1 loaded into memory.\nFile test_other_1 loaded into memory.\nFile test_person_1 loaded into memory.\nFile test_deposit_1 loaded into memory.\nFile test_debitcard_1 loaded into memory.\nFile test_credit_bureau_a_2_3 loaded into memory.\nFile test_credit_bureau_a_2_9 loaded into memory.\nFile test_credit_bureau_a_2_2 loaded into memory.\nFile test_credit_bureau_a_2_11 loaded into memory.\nFile test_credit_bureau_a_2_1 loaded into memory.\nFile test_credit_bureau_a_2_6 loaded into memory.\nFile test_credit_bureau_a_2_5 loaded into memory.\nFile test_credit_bureau_a_2_0 loaded into memory.\nFile test_credit_bureau_a_2_7 loaded into memory.\nFile test_credit_bureau_a_2_10 loaded into memory.\nFile test_credit_bureau_a_2_8 loaded into memory.\nFile test_credit_bureau_a_2_4 loaded into memory.\nFile test_credit_bureau_b_2 loaded into memory.\nMemory usage of dataframe \"df_train\" is 0.0432 MB.\nMemory usage of dataframe \"df_train\" became 0.0311 MB.\nMemory usage of dataframe \"df_test\" is 0.0184 MB.\nMemory usage of dataframe \"df_test\" became 0.0172 MB.\nTest data shape: (10, 471)\n","output_type":"stream"}]},{"cell_type":"code","source":"num_cols = ['assignmentdate_238D', 'assignmentdate_4527235D', 'birthdate_574D', 'contractssum_5085716L', 'dateofbirth_337D', 'days120_123L', 'days180_256L', 'days30_165L', 'days360_512L', 'days90_310L', 'firstquarter_103L', 'fourthquarter_440L', 'numberofqueries_373L', 'pmtaverage_3A', 'pmtaverage_4527227A', 'pmtcount_4527229L', 'pmtcount_693L', 'pmtscount_423L', 'pmtssum_45A', 'responsedate_1012D', 'responsedate_4527233D', 'responsedate_4917613D', 'secondquarter_766L', 'thirdquarter_1082L', 'actualdpdtolerance_344P', 'amtinstpaidbefduel24m_4187115A', 'annuity_780A', 'annuitynextmonth_57A', 'applicationcnt_361L', 'applications30d_658L', 'applicationscnt_1086L', 'applicationscnt_464L', 'applicationscnt_629L', 'applicationscnt_867L', 'avgdbddpdlast24m_3658932P', 'avgdbddpdlast3m_4187120P', 'avgdbdtollast24m_4525197P', 'avgdpdtolclosure24_3658938P', 'avginstallast24m_3658937A', 'avglnamtstart24m_4525187A', 'avgmaxdpdlast9m_3716943P', 'avgoutstandbalancel6m_4187114A', 'avgpmtlast12m_4525200A', 'clientscnt12m_3712952L', 'clientscnt3m_3712950L', 'clientscnt6m_3712949L', 'clientscnt_100L', 'clientscnt_1022L', 'clientscnt_1071L', 'clientscnt_1130L', 'clientscnt_157L', 'clientscnt_257L', 'clientscnt_304L', 'clientscnt_360L', 'clientscnt_493L', 'clientscnt_533L', 'clientscnt_887L', 'clientscnt_946L', 'cntincpaycont9m_3716944L', 'cntpmts24_3658933L', 'commnoinclast6m_3546845L', 'credamount_770A', 'currdebt_22A', 'currdebtcredtyperange_828A', 'datefirstoffer_1144D', 'datelastinstal40dpd_247D', 'datelastunpaid_3546854D', 'daysoverduetolerancedd_3976961L', 'deferredmnthsnum_166L', 'disbursedcredamount_1113A', 'downpmt_116A', 'dtlastpmtallstes_4499206D', 'eir_270L', 'firstclxcampaign_1125D', 'firstdatedue_489D', 'homephncnt_628L', 'inittransactionamount_650A', 'interestrate_311L', 'lastactivateddate_801D', 'lastapplicationdate_877D', 'lastapprcredamount_781A', 'lastapprdate_640D', 'lastdelinqdate_224D', 'lastrejectcredamount_222A', 'lastrejectdate_50D', 'maininc_215A', 'mastercontrelectronic_519L', 'mastercontrexist_109L', 'maxannuity_159A', 'maxdbddpdlast1m_3658939P', 'maxdbddpdtollast12m_3658940P', 'maxdbddpdtollast6m_4187119P', 'maxdebt4_972A', 'maxdpdfrom6mto36m_3546853P', 'maxdpdinstldate_3546855D', 'maxdpdinstlnum_3546846P', 'maxdpdlast12m_727P', 'maxdpdlast24m_143P', 'maxdpdlast3m_392P', 'maxdpdlast6m_474P', 'maxdpdlast9m_1059P', 'maxdpdtolerance_374P', 'maxinstallast24m_3658928A', 'maxlnamtstart6m_4525199A', 'maxoutstandbalancel12m_4187113A', 'maxpmtlast3m_4525190A', 'mindbddpdlast24m_3658935P', 'mindbdtollast24m_4525191P', 'mobilephncnt_593L', 'monthsannuity_845L', 'numactivecreds_622L', 'numactivecredschannel_414L', 'numactiverelcontr_750L', 'numcontrs3months_479L', 'numincomingpmts_3546848L', 'numinstlallpaidearly3d_817L', 'numinstls_657L', 'numinstlsallpaid_934L', 'numinstlswithdpd10_728L', 'numinstlswithdpd5_4187116L', 'numinstlswithoutdpd_562L', 'numinstmatpaidtearly2d_4499204L', 'numinstpaid_4499208L', 'numinstpaidearly3d_3546850L', 'numinstpaidearly3dest_4493216L', 'numinstpaidearly5d_1087L', 'numinstpaidearly5dest_4493211L', 'numinstpaidearly5dobd_4499205L', 'numinstpaidearly_338L', 'numinstpaidearlyest_4493214L', 'numinstpaidlastcontr_4325080L', 'numinstpaidlate1d_3546852L', 'numinstregularpaid_973L', 'numinstregularpaidest_4493210L', 'numinsttopaygr_769L', 'numinsttopaygrest_4493213L', 'numinstunpaidmax_3546851L', 'numinstunpaidmaxest_4493212L', 'numnotactivated_1143L', 'numpmtchanneldd_318L', 'numrejects9m_859L', 'pctinstlsallpaidearl3d_427L', 'pctinstlsallpaidlat10d_839L', 'pctinstlsallpaidlate1d_3546856L', 'pctinstlsallpaidlate4d_3546849L', 'pctinstlsallpaidlate6d_3546844L', 'pmtnum_254L', 'posfpd10lastmonth_333P', 'posfpd30lastmonth_3976960P', 'posfstqpd30lastmonth_3976962P', 'price_1097A', 'sellerplacecnt_915L', 'sellerplacescnt_216L', 'sumoutstandtotal_3546847A', 'sumoutstandtotalest_4493215A', 'totaldebt_9A', 'totalsettled_863A', 'totinstallast1m_4525188A', 'validfrom_1069D', 'max_actualdpd_943P', 'max_annuity_853A', 'max_approvaldate_319D', 'max_byoccupationinc_3656910L', 'max_childnum_21L', 'max_creationdate_885D', 'max_credacc_actualbalance_314A', 'max_credacc_credlmt_575A', 'max_credacc_maxhisbal_375A', 'max_credacc_minhisbal_90A', 'max_credacc_transactions_402L', 'max_credamount_590A', 'max_currdebt_94A', 'max_dateactivated_425D', 'max_downpmt_134A', 'max_dtlastpmt_581D', 'max_dtlastpmtallstes_3545839D', 'max_employedfrom_700D', 'max_firstnonzeroinstldate_307D', 'max_mainoccupationinc_437A', 'max_maxdpdtolerance_577P', 'max_num_group1', 'max_outstandingdebt_522A', 'max_pmtnum_8L', 'max_revolvingaccount_394A', 'max_tenor_203L', 'mean_actualdpd_943P', 'mean_annuity_853A', 'mean_approvaldate_319D', 'mean_creationdate_885D', 'mean_credacc_actualbalance_314A', 'mean_credacc_credlmt_575A', 'mean_credacc_maxhisbal_375A', 'mean_credacc_minhisbal_90A', 'mean_credamount_590A', 'mean_currdebt_94A', 'mean_dateactivated_425D', 'mean_downpmt_134A', 'mean_dtlastpmt_581D', 'mean_dtlastpmtallstes_3545839D', 'mean_employedfrom_700D', 'mean_firstnonzeroinstldate_307D', 'mean_mainoccupationinc_437A', 'mean_maxdpdtolerance_577P', 'mean_outstandingdebt_522A', 'mean_revolvingaccount_394A', 'var_actualdpd_943P', 'var_annuity_853A', 'var_credacc_credlmt_575A', 'var_credamount_590A', 'var_currdebt_94A', 'var_downpmt_134A', 'var_mainoccupationinc_437A', 'var_maxdpdtolerance_577P', 'var_outstandingdebt_522A', 'max_amount_4527230A', 'max_num_group1_3', 'max_recorddate_4527225D', 'mean_amount_4527230A', 'mean_recorddate_4527225D', 'var_amount_4527230A', 'max_amount_4917619A', 'max_deductiondate_4917603D', 'max_num_group1_4', 'mean_amount_4917619A', 'mean_deductiondate_4917603D', 'var_amount_4917619A', 'max_num_group1_5', 'max_pmtamount_36A', 'max_processingdate_168D', 'mean_pmtamount_36A', 'mean_processingdate_168D', 'var_pmtamount_36A', 'max_annualeffectiverate_199L', 'max_annualeffectiverate_63L', 'max_contractsum_5085717L', 'max_credlmt_230A', 'max_credlmt_935A', 'max_dateofcredend_289D', 'max_dateofcredend_353D', 'max_dateofcredstart_181D', 'max_dateofcredstart_739D', 'max_dateofrealrepmt_138D', 'max_debtoutstand_525A', 'max_debtoverdue_47A', 'max_dpdmax_139P', 'max_dpdmax_757P', 'max_dpdmaxdatemonth_442T', 'max_dpdmaxdatemonth_89T', 'max_dpdmaxdateyear_596T', 'max_dpdmaxdateyear_896T', 'max_instlamount_768A', 'max_instlamount_852A', 'max_lastupdate_1112D', 'max_lastupdate_388D', 'max_monthlyinstlamount_332A', 'max_monthlyinstlamount_674A', 'max_nominalrate_281L', 'max_nominalrate_498L', 'max_num_group1_6', 'max_numberofcontrsvalue_258L', 'max_numberofcontrsvalue_358L', 'max_numberofinstls_229L', 'max_numberofinstls_320L', 'max_numberofoutstandinstls_520L', 'max_numberofoutstandinstls_59L', 'max_numberofoverdueinstlmax_1039L', 'max_numberofoverdueinstlmax_1151L', 'max_numberofoverdueinstlmaxdat_148D', 'max_numberofoverdueinstlmaxdat_641D', 'max_numberofoverdueinstls_725L', 'max_numberofoverdueinstls_834L', 'max_outstandingamount_354A', 'max_outstandingamount_362A', 'max_overdueamount_31A', 'max_overdueamount_659A', 'max_overdueamountmax2_14A', 'max_overdueamountmax2_398A', 'max_overdueamountmax2date_1002D', 'max_overdueamountmax2date_1142D', 'max_overdueamountmax_155A', 'max_overdueamountmax_35A', 'max_overdueamountmaxdatemonth_284T', 'max_overdueamountmaxdatemonth_365T', 'max_overdueamountmaxdateyear_2T', 'max_overdueamountmaxdateyear_994T', 'max_periodicityofpmts_1102L', 'max_periodicityofpmts_837L', 'max_prolongationcount_1120L', 'max_refreshdate_3813885D', 'max_residualamount_488A', 'max_residualamount_856A', 'max_totalamount_6A', 'max_totalamount_996A', 'max_totaldebtoverduevalue_178A', 'max_totaldebtoverduevalue_718A', 'max_totaloutstanddebtvalue_39A', 'max_totaloutstanddebtvalue_668A', 'mean_credlmt_230A', 'mean_credlmt_935A', 'mean_dateofcredend_289D', 'mean_dateofcredend_353D', 'mean_dateofcredstart_181D', 'mean_dateofcredstart_739D', 'mean_dateofrealrepmt_138D', 'mean_debtoutstand_525A', 'mean_debtoverdue_47A', 'mean_dpdmax_139P', 'mean_dpdmax_757P', 'mean_instlamount_768A', 'mean_instlamount_852A', 'mean_lastupdate_1112D', 'mean_lastupdate_388D', 'mean_monthlyinstlamount_332A', 'mean_monthlyinstlamount_674A', 'mean_numberofoverdueinstlmaxdat_148D', 'mean_numberofoverdueinstlmaxdat_641D', 'mean_outstandingamount_354A', 'mean_outstandingamount_362A', 'mean_overdueamount_31A', 'mean_overdueamount_659A', 'mean_overdueamountmax2_14A', 'mean_overdueamountmax2_398A', 'mean_overdueamountmax2date_1002D', 'mean_overdueamountmax2date_1142D', 'mean_overdueamountmax_155A', 'mean_overdueamountmax_35A', 'mean_refreshdate_3813885D', 'mean_residualamount_488A', 'mean_residualamount_856A', 'mean_totalamount_6A', 'mean_totalamount_996A', 'mean_totaldebtoverduevalue_178A', 'mean_totaldebtoverduevalue_718A', 'mean_totaloutstanddebtvalue_39A', 'mean_totaloutstanddebtvalue_668A', 'var_credlmt_230A', 'var_credlmt_935A', 'var_dpdmax_139P', 'var_dpdmax_757P', 'var_instlamount_768A', 'var_instlamount_852A', 'var_monthlyinstlamount_332A', 'var_monthlyinstlamount_674A', 'var_outstandingamount_354A', 'var_outstandingamount_362A', 'var_overdueamount_31A', 'var_overdueamount_659A', 'var_overdueamountmax2_14A', 'var_overdueamountmax2_398A', 'var_overdueamountmax_155A', 'var_overdueamountmax_35A', 'var_residualamount_488A', 'var_residualamount_856A', 'var_totalamount_6A', 'var_totalamount_996A', 'max_birth_259D', 'max_empl_employedfrom_271D', 'max_mainoccupationinc_384A', 'max_num_group1_9', 'max_personindex_1023L', 'max_persontype_1072L', 'max_persontype_792L', 'mean_birth_259D', 'mean_empl_employedfrom_271D', 'mean_mainoccupationinc_384A', 'max_amount_416A', 'max_num_group1_10', 'max_openingdate_313D', 'mean_amount_416A', 'mean_openingdate_313D', 'max_num_group1_11', 'max_openingdate_857D', 'mean_openingdate_857D', 'max_collater_valueofguarantee_1124L', 'max_collater_valueofguarantee_876L', 'max_num_group1_12', 'max_num_group2', 'max_pmts_dpd_1073P', 'max_pmts_dpd_303P', 'max_pmts_month_158T', 'max_pmts_month_706T', 'max_pmts_overdue_1140A', 'max_pmts_overdue_1152A', 'max_pmts_year_1139T', 'max_pmts_year_507T', 'mean_pmts_dpd_1073P', 'mean_pmts_dpd_303P', 'mean_pmts_overdue_1140A', 'mean_pmts_overdue_1152A', 'var_pmts_dpd_1073P', 'var_pmts_dpd_303P', 'var_pmts_overdue_1140A', 'var_pmts_overdue_1152A', 'day']\n# except \"case_id\", \"year\", \"month\", \"week_num\", \"target\"\nfor col in num_cols:\n    df_train = df_train.with_columns(\n        pl.col(col).fill_null(-0.1)\n    )\nfor col in num_cols:\n    df_test = df_test.with_columns(\n        pl.col(col).fill_null(-0.1)\n    )","metadata":{"papermill":{"duration":2.602758,"end_time":"2024-05-22T00:21:51.037304","exception":false,"start_time":"2024-05-22T00:21:48.434546","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:31:16.293725Z","iopub.execute_input":"2024-05-26T13:31:16.294079Z","iopub.status.idle":"2024-05-26T13:31:18.337652Z","shell.execute_reply.started":"2024-05-26T13:31:16.294054Z","shell.execute_reply":"2024-05-26T13:31:18.336578Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df_train, cat_cols = Utility.to_pandas(df_train)\ndf_test, cat_cols = Utility.to_pandas(df_test, cat_cols)","metadata":{"papermill":{"duration":26.158306,"end_time":"2024-05-22T00:22:17.207841","exception":false,"start_time":"2024-05-22T00:21:51.049535","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:31:18.339070Z","iopub.execute_input":"2024-05-26T13:31:18.339847Z","iopub.status.idle":"2024-05-26T13:31:41.663365Z","shell.execute_reply.started":"2024-05-26T13:31:18.339811Z","shell.execute_reply":"2024-05-26T13:31:41.662246Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(\"train data shape:\\t\", df_train.shape)\nprint(\"test data shape:\\t\", df_test.shape)","metadata":{"papermill":{"duration":0.024493,"end_time":"2024-05-22T00:22:17.244971","exception":false,"start_time":"2024-05-22T00:22:17.220478","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:31:41.664872Z","iopub.execute_input":"2024-05-26T13:31:41.665612Z","iopub.status.idle":"2024-05-26T13:31:41.670945Z","shell.execute_reply.started":"2024-05-26T13:31:41.665572Z","shell.execute_reply":"2024-05-26T13:31:41.670047Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"train data shape:\t (1526659, 472)\ntest data shape:\t (10, 471)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# pca","metadata":{"papermill":{"duration":0.012016,"end_time":"2024-05-22T00:22:17.269492","exception":false,"start_time":"2024-05-22T00:22:17.257476","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = joblib.load('/kaggle/input/pipe2final/pca28.joblib')\npca_columns = [f'PCA_int_{i+1}' for i in range(28)]","metadata":{"papermill":{"duration":0.031485,"end_time":"2024-05-22T00:22:17.313500","exception":false,"start_time":"2024-05-22T00:22:17.282015","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:31:41.671900Z","iopub.execute_input":"2024-05-26T13:31:41.672150Z","iopub.status.idle":"2024-05-26T13:31:41.701940Z","shell.execute_reply.started":"2024-05-26T13:31:41.672129Z","shell.execute_reply":"2024-05-26T13:31:41.701253Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"principal_components_train = pca.transform(df_train[num_cols])\ndf_pca_train = pd.DataFrame(principal_components_train, columns=pca_columns, index=df_train.index)\ndf_train = pd.concat([df_train, df_pca_train], axis=1)\n# joblib.dump(pca, \"pca28.joblib\")","metadata":{"papermill":{"duration":16.476433,"end_time":"2024-05-22T00:22:33.802303","exception":false,"start_time":"2024-05-22T00:22:17.325870","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:31:41.702917Z","iopub.execute_input":"2024-05-26T13:31:41.703181Z","iopub.status.idle":"2024-05-26T13:31:57.042537Z","shell.execute_reply.started":"2024-05-26T13:31:41.703158Z","shell.execute_reply":"2024-05-26T13:31:57.041432Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"principal_components_test = pca.transform(df_test[num_cols])\ndf_pca_test = pd.DataFrame(principal_components_test, columns=pca_columns, index=df_test.index)\ndf_test = pd.concat([df_test, df_pca_test], axis=1)","metadata":{"papermill":{"duration":0.038825,"end_time":"2024-05-22T00:22:33.854298","exception":false,"start_time":"2024-05-22T00:22:33.815473","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:31:57.044120Z","iopub.execute_input":"2024-05-26T13:31:57.044535Z","iopub.status.idle":"2024-05-26T13:31:57.064946Z","shell.execute_reply.started":"2024-05-26T13:31:57.044483Z","shell.execute_reply":"2024-05-26T13:31:57.063898Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"del df_pca_train, df_pca_test, principal_components_train, principal_components_test\ngc.collect()","metadata":{"papermill":{"duration":0.153065,"end_time":"2024-05-22T00:22:34.019982","exception":false,"start_time":"2024-05-22T00:22:33.866917","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:31:57.066339Z","iopub.execute_input":"2024-05-26T13:31:57.067053Z","iopub.status.idle":"2024-05-26T13:31:57.191144Z","shell.execute_reply.started":"2024-05-26T13:31:57.067017Z","shell.execute_reply":"2024-05-26T13:31:57.190110Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"print(\"train data shape:\\t\", df_train.shape)\nprint(\"test data shape:\\t\", df_test.shape)","metadata":{"papermill":{"duration":0.024783,"end_time":"2024-05-22T00:22:34.057634","exception":false,"start_time":"2024-05-22T00:22:34.032851","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:31:57.192567Z","iopub.execute_input":"2024-05-26T13:31:57.192878Z","iopub.status.idle":"2024-05-26T13:31:57.202690Z","shell.execute_reply.started":"2024-05-26T13:31:57.192852Z","shell.execute_reply":"2024-05-26T13:31:57.201726Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"train data shape:\t (1526659, 500)\ntest data shape:\t (10, 499)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# - - - - -- - - - - - - ","metadata":{"papermill":{"duration":0.012277,"end_time":"2024-05-22T00:22:34.082725","exception":false,"start_time":"2024-05-22T00:22:34.070448","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class VotingModel(BaseEstimator, ClassifierMixin):\n\n    def __init__(self, estimators: list[BaseEstimator]):\n        super().__init__()\n        self.estimators = estimators\n\n    def fit(self, X, y=None):\n        return self\n\n    def predict(self, X):\n        y_preds = [estimator.predict(X) for estimator in self.estimators]\n        return np.mean(y_preds, axis=0)\n\n    def predict_proba(self, X):\n        y_preds = [estimator.predict_proba(X) for estimator in self.estimators]\n        return np.mean(y_preds, axis=0)","metadata":{"papermill":{"duration":0.02617,"end_time":"2024-05-22T00:22:34.121790","exception":false,"start_time":"2024-05-22T00:22:34.095620","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:31:57.203819Z","iopub.execute_input":"2024-05-26T13:31:57.204173Z","iopub.status.idle":"2024-05-26T13:31:57.213414Z","shell.execute_reply.started":"2024-05-26T13:31:57.204139Z","shell.execute_reply":"2024-05-26T13:31:57.212722Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df_subm: pd.DataFrame = pd.read_csv(ROOT / \"sample_submission.csv\")\ndf_subm = df_subm.set_index(\"case_id\")\n\ndevice: str = \"gpu\"\nDRY_RUN = True if df_subm.shape[0] == 10 else False\nif DRY_RUN:\n    df_train = df_train.iloc[:50000]\n    est_cnt: int = 600\nprint(device)","metadata":{"papermill":{"duration":0.032989,"end_time":"2024-05-22T00:22:34.167590","exception":false,"start_time":"2024-05-22T00:22:34.134601","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:31:57.214440Z","iopub.execute_input":"2024-05-26T13:31:57.214804Z","iopub.status.idle":"2024-05-26T13:31:57.242272Z","shell.execute_reply.started":"2024-05-26T13:31:57.214773Z","shell.execute_reply":"2024-05-26T13:31:57.241406Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"gpu\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"train data shape:\\t\", df_train.shape)\nprint(\"test data shape:\\t\", df_test.shape)","metadata":{"papermill":{"duration":0.023921,"end_time":"2024-05-22T00:22:34.204806","exception":false,"start_time":"2024-05-22T00:22:34.180885","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:31:57.243440Z","iopub.execute_input":"2024-05-26T13:31:57.243828Z","iopub.status.idle":"2024-05-26T13:31:57.250717Z","shell.execute_reply.started":"2024-05-26T13:31:57.243797Z","shell.execute_reply":"2024-05-26T13:31:57.249689Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"train data shape:\t (50000, 500)\ntest data shape:\t (10, 499)\n","output_type":"stream"}]},{"cell_type":"code","source":"X = df_train.drop(columns=[\"target\", \"case_id\", \"week_num\"])\ny = df_train[\"target\"]\n\nweeks = df_train[\"week_num\"]\n\ndel df_train\ngc.collect()\n\ncv = StratifiedGroupKFold(n_splits=5, shuffle=False)\n\nparams1 = {\n    \"boosting_type\": \"gbdt\",\n    \"objective\": \"binary\",\n    \"metric\": \"auc\",\n    \"max_depth\": 10,  \n    \"learning_rate\": 0.05,\n    \"n_estimators\": 2000,  \n    \"colsample_bytree\": 0.8,\n    \"colsample_bynode\": 0.8,\n    \"verbose\": -1,\n    \"random_state\": 8268,\n    \"reg_alpha\": 0.1,\n    \"reg_lambda\": 10,\n    \"extra_trees\":True,\n    'num_leaves':64,\n    'categorical_feature ': 'auto',\n    \"device\": 'gpu', \n    \"max_bin\":245,\n    \"verbose\": -1,\n}\n\nparams2 = {\n    \"boosting_type\": \"gbdt\",\n    \"colsample_bynode\": 0.8,\n    \"colsample_bytree\": 0.8,\n    \"device\": 'gpu', \n    \"extra_trees\": True,\n    \"learning_rate\": 0.03,\n    \"l1_regularization\": 0.1,\n    \"l2_regularization\": 10,\n    \"max_depth\": 16,\n    \"metric\": \"auc\",\n    \"n_estimators\": 2000,\n    \"num_leaves\": 72,\n    \"objective\": \"binary\",\n    \"random_state\": 9217,\n    \"verbose\": -1,\n    \"max_bin\":245,\n}\n\nfitted_models_cat = []\nfitted_models_lgb = []\n\ncv_scores_cat = []\ncv_scores_lgb = []\n\niter_cnt = 0\nfor idx_train, idx_valid in cv.split(X, y, groups=weeks):\n    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n\n    X_train[cat_cols] = X_train[cat_cols].astype(\"category\")\n    X_valid[cat_cols] = X_valid[cat_cols].astype(\"category\")\n\n    if iter_cnt % 2 == 0:\n        model = lgb.LGBMClassifier(**params1)\n    else:\n        model = lgb.LGBMClassifier(**params2)\n\n    model.fit(\n        X_train,\n        y_train,\n        eval_set=[(X_valid, y_valid)],\n        callbacks=[lgb.log_evaluation(200), lgb.early_stopping(100)],\n    )\n    fitted_models_lgb.append(model)\n#     joblib.dump(model, f\"lgb_{iter_cnt}.joblib\")\n\n    iter_cnt += 1\n\n\nfor i in range(5):\n    cat_model = joblib.load(f'/kaggle/input/pipe2final/cat_{i}.joblib')\n    fitted_models_cat.append(cat_model)\n    \nmodel = VotingModel(fitted_models_lgb+fitted_models_cat)\n\n\ndel X, y\ngc.collect()\n\nmodel","metadata":{"papermill":{"duration":26270.344082,"end_time":"2024-05-22T07:40:24.562156","exception":false,"start_time":"2024-05-22T00:22:34.218074","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:31:57.252337Z","iopub.execute_input":"2024-05-26T13:31:57.252676Z","iopub.status.idle":"2024-05-26T13:33:17.712224Z","shell.execute_reply.started":"2024-05-26T13:31:57.252651Z","shell.execute_reply":"2024-05-26T13:33:17.711210Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Training until validation scores don't improve for 100 rounds\n[200]\tvalid_0's auc: 0.815111\nEarly stopping, best iteration is:\n[160]\tvalid_0's auc: 0.815579\nTraining until validation scores don't improve for 100 rounds\n[200]\tvalid_0's auc: 0.834263\nEarly stopping, best iteration is:\n[278]\tvalid_0's auc: 0.836904\nTraining until validation scores don't improve for 100 rounds\n[200]\tvalid_0's auc: 0.8334\nEarly stopping, best iteration is:\n[299]\tvalid_0's auc: 0.835816\nTraining until validation scores don't improve for 100 rounds\n[200]\tvalid_0's auc: 0.826546\nEarly stopping, best iteration is:\n[216]\tvalid_0's auc: 0.82792\nTraining until validation scores don't improve for 100 rounds\n[200]\tvalid_0's auc: 0.838375\nEarly stopping, best iteration is:\n[290]\tvalid_0's auc: 0.841265\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"VotingModel(estimators=[LGBMClassifier(categorical_feature ='auto',\n                                       colsample_bynode=0.8,\n                                       colsample_bytree=0.8, device='gpu',\n                                       extra_trees=True, learning_rate=0.05,\n                                       max_bin=245, max_depth=10, metric='auc',\n                                       n_estimators=2000, num_leaves=64,\n                                       objective='binary', random_state=8268,\n                                       reg_alpha=0.1, reg_lambda=10,\n                                       verbose=-1),\n                        LGBMClassifier(colsample_bynode=0.8,\n                                       colsample_...\n                                       objective='binary', random_state=8268,\n                                       reg_alpha=0.1, reg_lambda=10,\n                                       verbose=-1),\n                        <catboost.core.CatBoostClassifier object at 0x7aaddaef7490>,\n                        <catboost.core.CatBoostClassifier object at 0x7aa39ea1a8c0>,\n                        <catboost.core.CatBoostClassifier object at 0x7aa1ce319180>,\n                        <catboost.core.CatBoostClassifier object at 0x7aa39ea198d0>,\n                        <catboost.core.CatBoostClassifier object at 0x7aa1ce318430>])","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingModel(estimators=[LGBMClassifier(categorical_feature =&#x27;auto&#x27;,\n                                       colsample_bynode=0.8,\n                                       colsample_bytree=0.8, device=&#x27;gpu&#x27;,\n                                       extra_trees=True, learning_rate=0.05,\n                                       max_bin=245, max_depth=10, metric=&#x27;auc&#x27;,\n                                       n_estimators=2000, num_leaves=64,\n                                       objective=&#x27;binary&#x27;, random_state=8268,\n                                       reg_alpha=0.1, reg_lambda=10,\n                                       verbose=-1),\n                        LGBMClassifier(colsample_bynode=0.8,\n                                       colsample_...\n                                       objective=&#x27;binary&#x27;, random_state=8268,\n                                       reg_alpha=0.1, reg_lambda=10,\n                                       verbose=-1),\n                        &lt;catboost.core.CatBoostClassifier object at 0x7aaddaef7490&gt;,\n                        &lt;catboost.core.CatBoostClassifier object at 0x7aa39ea1a8c0&gt;,\n                        &lt;catboost.core.CatBoostClassifier object at 0x7aa1ce319180&gt;,\n                        &lt;catboost.core.CatBoostClassifier object at 0x7aa39ea198d0&gt;,\n                        &lt;catboost.core.CatBoostClassifier object at 0x7aa1ce318430&gt;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingModel</label><div class=\"sk-toggleable__content\"><pre>VotingModel(estimators=[LGBMClassifier(categorical_feature =&#x27;auto&#x27;,\n                                       colsample_bynode=0.8,\n                                       colsample_bytree=0.8, device=&#x27;gpu&#x27;,\n                                       extra_trees=True, learning_rate=0.05,\n                                       max_bin=245, max_depth=10, metric=&#x27;auc&#x27;,\n                                       n_estimators=2000, num_leaves=64,\n                                       objective=&#x27;binary&#x27;, random_state=8268,\n                                       reg_alpha=0.1, reg_lambda=10,\n                                       verbose=-1),\n                        LGBMClassifier(colsample_bynode=0.8,\n                                       colsample_...\n                                       objective=&#x27;binary&#x27;, random_state=8268,\n                                       reg_alpha=0.1, reg_lambda=10,\n                                       verbose=-1),\n                        &lt;catboost.core.CatBoostClassifier object at 0x7aaddaef7490&gt;,\n                        &lt;catboost.core.CatBoostClassifier object at 0x7aa39ea1a8c0&gt;,\n                        &lt;catboost.core.CatBoostClassifier object at 0x7aa1ce319180&gt;,\n                        &lt;catboost.core.CatBoostClassifier object at 0x7aa39ea198d0&gt;,\n                        &lt;catboost.core.CatBoostClassifier object at 0x7aa1ce318430&gt;])</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"X_test: pd.DataFrame = df_test.drop(columns=[\"week_num\"]).set_index(\"case_id\")\n\nX_test[cat_cols] = X_test[cat_cols].astype(\"category\")\n\ny_pred: pd.Series = pd.Series(model.predict_proba(X_test)[:, 1], index=X_test.index)\n\ndf_subm[\"score\"] = y_pred\n\ndisplay(df_subm)\n\ndel X_test, y_pred\ngc.collect()","metadata":{"papermill":{"duration":0.605676,"end_time":"2024-05-22T07:40:25.186309","exception":false,"start_time":"2024-05-22T07:40:24.580633","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:33:17.713728Z","iopub.execute_input":"2024-05-26T13:33:17.714831Z","iopub.status.idle":"2024-05-26T13:33:18.335483Z","shell.execute_reply.started":"2024-05-26T13:33:17.714794Z","shell.execute_reply":"2024-05-26T13:33:18.334597Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"            score\ncase_id          \n57543    0.008539\n57549    0.043683\n57551    0.002333\n57552    0.026517\n57569    0.141214\n57630    0.011883\n57631    0.037557\n57632    0.011924\n57633    0.032879\n57634    0.024221","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n    </tr>\n    <tr>\n      <th>case_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>57543</th>\n      <td>0.008539</td>\n    </tr>\n    <tr>\n      <th>57549</th>\n      <td>0.043683</td>\n    </tr>\n    <tr>\n      <th>57551</th>\n      <td>0.002333</td>\n    </tr>\n    <tr>\n      <th>57552</th>\n      <td>0.026517</td>\n    </tr>\n    <tr>\n      <th>57569</th>\n      <td>0.141214</td>\n    </tr>\n    <tr>\n      <th>57630</th>\n      <td>0.011883</td>\n    </tr>\n    <tr>\n      <th>57631</th>\n      <td>0.037557</td>\n    </tr>\n    <tr>\n      <th>57632</th>\n      <td>0.011924</td>\n    </tr>\n    <tr>\n      <th>57633</th>\n      <td>0.032879</td>\n    </tr>\n    <tr>\n      <th>57634</th>\n      <td>0.024221</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"df_lgb_pipe1 = pd.read_csv('sub1.csv').set_index('case_id')\ndf_subm['score2'] = df_lgb_pipe1['score']\n\ndisplay(df_subm)\n\ndel df_lgb_pipe1\ngc.collect()","metadata":{"papermill":{"duration":0.017795,"end_time":"2024-05-22T07:40:25.223774","exception":false,"start_time":"2024-05-22T07:40:25.205979","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-26T13:33:18.337007Z","iopub.execute_input":"2024-05-26T13:33:18.337297Z","iopub.status.idle":"2024-05-26T13:33:18.438391Z","shell.execute_reply.started":"2024-05-26T13:33:18.337273Z","shell.execute_reply":"2024-05-26T13:33:18.437482Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"            score    score2\ncase_id                    \n57543    0.008539  0.015884\n57549    0.043683  0.032191\n57551    0.002333  0.011103\n57552    0.026517  0.052811\n57569    0.141214  0.050107\n57630    0.011883  0.035200\n57631    0.037557  0.073221\n57632    0.011924  0.045776\n57633    0.032879  0.027966\n57634    0.024221  0.061248","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n      <th>score2</th>\n    </tr>\n    <tr>\n      <th>case_id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>57543</th>\n      <td>0.008539</td>\n      <td>0.015884</td>\n    </tr>\n    <tr>\n      <th>57549</th>\n      <td>0.043683</td>\n      <td>0.032191</td>\n    </tr>\n    <tr>\n      <th>57551</th>\n      <td>0.002333</td>\n      <td>0.011103</td>\n    </tr>\n    <tr>\n      <th>57552</th>\n      <td>0.026517</td>\n      <td>0.052811</td>\n    </tr>\n    <tr>\n      <th>57569</th>\n      <td>0.141214</td>\n      <td>0.050107</td>\n    </tr>\n    <tr>\n      <th>57630</th>\n      <td>0.011883</td>\n      <td>0.035200</td>\n    </tr>\n    <tr>\n      <th>57631</th>\n      <td>0.037557</td>\n      <td>0.073221</td>\n    </tr>\n    <tr>\n      <th>57632</th>\n      <td>0.011924</td>\n      <td>0.045776</td>\n    </tr>\n    <tr>\n      <th>57633</th>\n      <td>0.032879</td>\n      <td>0.027966</td>\n    </tr>\n    <tr>\n      <th>57634</th>\n      <td>0.024221</td>\n      <td>0.061248</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"df_subm['score'] = df_subm[['score', 'score2']].mean(axis=1)\ndf_subm.drop(columns=['score2'], inplace=True)\ndisplay(df_subm)","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:33:18.439598Z","iopub.execute_input":"2024-05-26T13:33:18.439878Z","iopub.status.idle":"2024-05-26T13:33:18.451753Z","shell.execute_reply.started":"2024-05-26T13:33:18.439854Z","shell.execute_reply":"2024-05-26T13:33:18.450777Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"            score\ncase_id          \n57543    0.012212\n57549    0.037937\n57551    0.006718\n57552    0.039664\n57569    0.095661\n57630    0.023542\n57631    0.055389\n57632    0.028850\n57633    0.030423\n57634    0.042735","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n    </tr>\n    <tr>\n      <th>case_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>57543</th>\n      <td>0.012212</td>\n    </tr>\n    <tr>\n      <th>57549</th>\n      <td>0.037937</td>\n    </tr>\n    <tr>\n      <th>57551</th>\n      <td>0.006718</td>\n    </tr>\n    <tr>\n      <th>57552</th>\n      <td>0.039664</td>\n    </tr>\n    <tr>\n      <th>57569</th>\n      <td>0.095661</td>\n    </tr>\n    <tr>\n      <th>57630</th>\n      <td>0.023542</td>\n    </tr>\n    <tr>\n      <th>57631</th>\n      <td>0.055389</td>\n    </tr>\n    <tr>\n      <th>57632</th>\n      <td>0.028850</td>\n    </tr>\n    <tr>\n      <th>57633</th>\n      <td>0.030423</td>\n    </tr>\n    <tr>\n      <th>57634</th>\n      <td>0.042735</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_subm.to_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-05-26T13:33:18.452995Z","iopub.execute_input":"2024-05-26T13:33:18.453300Z","iopub.status.idle":"2024-05-26T13:33:18.464948Z","shell.execute_reply.started":"2024-05-26T13:33:18.453269Z","shell.execute_reply":"2024-05-26T13:33:18.464054Z"},"trusted":true},"execution_count":25,"outputs":[]}]}